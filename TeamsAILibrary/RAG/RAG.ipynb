{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Include the following in actions.json file for the prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "        \"name\": \"GetMargiesTravelInfo\",\n",
    "        \"description\": \"Gets information about Margie's Travel from Azure AI Search's index and vectorstore\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"user_query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"the query of the user about Margie's Travel Agency\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"user_query\"\n",
    "            ]\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Include the following import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding Generator Function - in bot.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(client, text):\n",
    "    embedding_model = \"YOUR_EMBEDDING_MODEL_NAME\"\n",
    "    \n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model = embedding_model\n",
    "    )\n",
    "    \n",
    "    embeddings=response.model_dump()\n",
    "    return embeddings['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The AI Action code - in bot.py file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot_app.ai.action(\"GetMargiesTravelInfo\")\n",
    "async def get_margies_travel_info(context: TurnContext, state: TurnState):\n",
    "    \n",
    "    # Fetching the user query from the context\n",
    "    user_query = str(context.data[\"user_query\"]) if context.data[\"user_query\"] else \"null\"\n",
    "    \n",
    "    # Creating an instance of the AzureOpenAI client\n",
    "    azure_openai_client=AzureOpenAI(\n",
    "        api_key = config.AZURE_OPENAI_API_KEY,\n",
    "        api_version = \"2024-02-15-preview\",\n",
    "        azure_endpoint = config.AZURE_OPENAI_ENDPOINT\n",
    "    )\n",
    "    \n",
    "    # Generating vector embeddings for the user query\n",
    "    vectorised_user_query = generate_embeddings(azure_openai_client, user_query)\n",
    "    \n",
    "    url = f\"YOUR_AZURE_AI_SEARCH_ENDPOINT/indexes/YOUR_INDEX_NAME/docs/search?api-version=2023-11-01\"\n",
    "    \n",
    "    headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"api-key\": \"YOUR_AI_SEARCH_API_KEY\"\n",
    "        }\n",
    "        \n",
    "    body =   {\n",
    "            \"count\": True,\n",
    "            \"select\": \"chunk\",\n",
    "            \"vectorQueries\": [\n",
    "                {\n",
    "                    \"vector\": vectorised_user_query,\n",
    "                    \"k\": 3,\n",
    "                    \"fields\": \"text_vector\",\n",
    "                    \"kind\": \"vector\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "    response = requests.post(url, headers=headers, data=json.dumps(body))\n",
    "    documents = response.json()['value']\n",
    "    \n",
    "    grounding_knowledge = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        grounding_knowledge.append(dict(\n",
    "            {\n",
    "                \"chunk\": doc['chunk'],\n",
    "                \"score\": doc['@search.score']\n",
    "                \n",
    "            }\n",
    "        ))\n",
    "    \n",
    "    await context.send_activity(f\"fetching supporting knowledge for your query\")\n",
    "    return f\"the grounding knowledge is {grounding_knowledge}\" "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
